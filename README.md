![InstructSharp â€“ unified .NET LLM SDK banner showing provider logos](assets/banner.jpg)

<p align="center">
  <a href="https://www.nuget.org/packages/InstructSharp"><img src="https://img.shields.io/nuget/v/InstructSharp?style=for-the-badge&color=brightgreen" alt="NuGet Version"></a>
  <a href="https://github.com/jonathanfavorite/InstructSharp/actions"><img src="https://img.shields.io/github/actions/workflow/status/jonathanfavorite/InstructSharp/build.yml?style=for-the-badge" alt="Build Status"></a>
  <a href="LICENSE"><img src="https://img.shields.io/github/license/jonathanfavorite/InstructSharp?style=for-the-badge&color=blue" alt="MIT License"></a>
</p>

---

# InstructSharp

**InstructSharp** is a **highâ€‘performance, providerâ€‘agnostic .NET SDK** that turns **largeâ€‘languageâ€‘model requests into oneâ€‘line calls** and **structured JSON responses**. âœ¨

*Seamlessly swap between OpenAIÂ ChatGPT, AnthropicÂ Claude, GoogleÂ Gemini, X.AIÂ Grok, DeepSeek, or MetaÂ LLaMA without rewriting a single line of business logic.*

> **TL;DR** â€“ Install the package, define a POCO, call `QueryAsync<T>()`, get stronglyâ€‘typed results. âœ…

---

## ğŸ“‘ Table of Contents

1. [Key Features](#key-features)
2. [Quick Install](#quick-install)
3. [Hello, World](#hello-world)
4. [Provider Matrix](#provider-matrix)
5. [Advanced Usage](#advanced-usage)
6. [Performance Notes](#performance-notes)
7. [Roadmap](#roadmap)
8. [Contributing](#contributing)
9. [License](#license)

---

## Key Features

| ğŸš€ Feature                  | Description                                                                                   |
| --------------------------- | --------------------------------------------------------------------------------------------- |
| **Multiâ€‘Provider**          | One unified client for **ChatGPT, Claude, Gemini, Grok, DeepSeek, LLaMA** â€“ more coming.      |
| **Strong Typing**           | Pass any C# POCO â†’ receive a `LLMResponse<T>` with fullyâ€‘deserialized data.                   |
| **Consistent API**          | Every client exposes `QueryAsync<T>(request)` so swapping vendors is a oneâ€‘line change.       |
| **JSON Schema Enforcement** | Automatic schema generation via **NJsonSchema**, keeping responses strict & safe.             |
| **Minimal Setup**           | Install â†’ add API key â†’ ship. Works in console apps, ASP.NET, Azure Functions, Blazor & more. |
| **Full .NETÂ 8 Support**     | Targets **net8.0** but runs on .NETÂ 6/7 via multiâ€‘target NuGet build.                         |
| **Tiny Footprint**          | Zero reflection at runtime, no heavy AI SDKs pulled in. PureÂ HTTP + `System.Text.Json`.       |

---

## Quick Install

```bash
# Package Manager
Install-Package InstructSharp

# .NET CLI
dotnet add package InstructSharp
```

> âš¡ **Tip** â€“ add `--prerelease` to grab nightly builds from CI.

---

## Hello, World

```csharp
using InstructSharp.Clients.ChatGPT;
using InstructSharp.Core;

class QuestionAnswer
{
    public string Question { get; set; }
    public string Answer   { get; set; }
}

var chat = new ChatGPTClient("YOUR_OPENAI_API_KEY");

var req = new ChatGPTRequest
{
    Model       = ChatGPTModels.GPT4oMini,
    Instruction = "Talk like a pirate.",
    Input       = "What is 2 + 2?"
};

var res = await chat.QueryAsync<QuestionAnswer>(req);
Console.WriteLine($"Aâ€¢ {res.Result.Answer}");
```

Want raw text? Simply use `string` instead of a POCO:

```csharp
var text = await chat.QueryAsync<string>(req);
```

---

## Provider Matrix

| Provider               | Client Class     | StructuredÂ JSON        | Streaming   | Docs                                      |
| ---------------------- | ---------------- | ---------------------- | ----------- | ----------------------------------------- |
| OpenAI ChatGPT         | `ChatGPTClient`  | âœ… JSONÂ Schema          | â³ (roadmap) | [link](https://platform.openai.com/docs/) |
| Anthropic ClaudeÂ 3     | `ClaudeClient`   | âœ… Tool Calls           | â³           | [link](https://docs.anthropic.com/)       |
| Google GeminiÂ 2.5      | `GeminiClient`   | âœ… `responseJsonSchema` | â³           | [link](https://ai.google.dev/)            |
| X.AI GrokÂ 3            | `GrokClient`     | âœ… JSONÂ Schema          | â³           | [link](https://platform.x.ai/)            |
| DeepSeek Chat          | `DeepSeekClient` | âœ… JSONÂ Object          | â³           | [link](https://deepseek.com/)             |
| Meta LLaMA (DeepInfra) | `LLamaClient`    | âœ… JSONÂ Object          | â³           | [link](https://deepinfra.com/)            |

> *Streaming support is on the roadmap â€“ follow the [issues](https://github.com/YOUR_GITHUB_HANDLE/InstructSharp/issues) to vote.*

---

## Advanced Usage

### ğŸ”’ Secure Configuration

```csharp
var http = new HttpClient {
    Timeout = TimeSpan.FromSeconds(15)
};
var chat = new ChatGPTClient(Environment.GetEnvironmentVariable("OPENAI_KEY"), http);
```

* `HttpClient` injection lets you share retry policies, logging handlers, or proxies.
* Add standard headers globally via `DefaultRequestHeaders`.

### ğŸ›ï¸ Tuning Parameters

Every request type exposes vendorâ€‘specific knobs such as `Temperature`, `TopP`, `MaxTokens`, etc. Set only what you need â€“ defaults are sane.

### ğŸ—‚ï¸ Error Handling

```csharp
try
{
    var res = await chat.QueryAsync<MyType>(req);
}
catch(HttpRequestException ex) when (ex.StatusCode == HttpStatusCode.TooManyRequests)
{
    // handle 429 rate limit
}
```

### ğŸ“‰ Token Usage

`LLMResponse<T>.Usage` returns prompt, response & total tokens. Use it for cost tracking or throttling.

---

## Performance Notes

* **No dynamic** â€“ all JSON is parsed with `System.Text.Json`. Fast.
* **Schema cache** â€“ Generated JSON schemas are cached perâ€‘type to avoid regeneration.
* **OneÂ HTTPÂ roundâ€‘trip** â€“ no second prompt to "format JSON"; the schema is sent in the first call.

Benchmarks live under `/benchmark` â€“ PRs welcome! ğŸï¸ğŸ’¨

---

## Roadmap

* [ ] ğŸ”„ Streaming completions
* [ ] ğŸ§© Function & tool call helpers
* [ ] ğŸ—ï¸ Automatic retries / exponential backâ€‘off
* [ ] ğŸ“ DocFX site with full API reference
* [ ] ğŸ† Benchmarks vs raw vendor SDKs

Have a feature in mind? [Open an issue](https://github.com/YOUR_GITHUB_HANDLE/InstructSharp/issues) or send a PR!

---

## Contributing

1. **Fork** the repo
2. `git clone` & `dotnet build` â€“ tests should pass
3. Create your branch: `git checkout -b feature/my-awesome`
4. Commit & push, then **open a PR**

### DevÂ Environment

* .NETÂ 8 SDK
* Optional: `direnv` / `dotenv` for API keys
* EditorConfig + Roslyn analyzers enforce style
